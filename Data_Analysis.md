# Data-Analysis
# --------------------------------------------------------------------------------------------------------------
# --------------------------------------------------------------------------------------------------------------
# --------------------------------------------------------------------------------------------------------------

#                                       || DATA ANALYSIS ||

# --------------------------------------------------------------------------------------------------------------
# --------------------------------------------------------------------------------------------------------------
# --------------------------------------------------------------------------------------------------------------

# --------------------------------------------------------------------------------------------------------------
# --------------------------------------------------------------------------------------------------------------
#                                        Linear Regression
# --------------------------------------------------------------------------------------------------------------
# --------------------------------------------------------------------------------------------------------------

# --------------------------------------------------------------------------------------------------------------
#                                       Order data from Tableau
# --------------------------------------------------------------------------------------------------------------

rm(list=ls())
TAB.ORDER_DUMMY <- read.table("C:/Yashwanth/Tableau Training/Orders.csv", 
           header = TRUE, sep = ",", quote = "\"", dec = "." ,fill=TRUE, comment.char="", as.is=TRUE)
TAB.ORDER_DUMMY <- TAB.ORDER_DUMMY[,c("Row_ID","Order_Priority","Order_Date","Ship_Date","Customer_ID","Customer_Name",
                                    "Ship_Mode","Customer_Segment","Product_Category","Product_Sub_Category","Product_Container",
                                    "Product_Name","Region","State_or_Province","City","Postal_Code","Unit_Price","Shipping_Cost",
                                    "Discount","Product_Base_Margin","Profit","Sale_Units","Sales_Dollar")]
  

TAB.ORDER <- read.table("C:/Yashwanth/Tableau Training/Orders_new.csv", 
                        header = TRUE, sep = ",", quote = "\"", dec = "." ,fill=TRUE, comment.char="", as.is=TRUE)
TAB.ORDER <- TAB.ORDER[,c(1:3,21,4,8,12:19,10,11,7,20,9,5,6)]

TAB.ORDER$Sales_Dollar <- as.numeric(TAB.ORDER$Sales_Dollar)
TAB.ORDER$Profit <- as.numeric(TAB.ORDER$Profit)

TAB.ORDER <- data.frame(with(TAB.ORDER,TAB.ORDER[order(Order_Date),]),row.names=NULL)
#TAB.ORDER$COGS <- round((TAB.ORDER[,21]-(TAB.ORDER[,21]*TAB.ORDER[,18])),2)
TAB.ORDER$Discount_price <- TAB.ORDER[,15]-TAB.ORDER[,22]
TAB.ORDER$Selling_Price_FP <- round(((TAB.ORDER[,21]-TAB.ORDER[,16])/TAB.ORDER[,20]),2)

TAB.ORDER$Unit_Margin <- round((TAB.ORDER[,18]*(TAB.ORDER[,22])),2)
TAB.ORDER$Cost_per_unit <- round((TAB.ORDER[,22]-TAB.ORDER[,24]),2)
TAB.ORDER$Cost_total <- round((TAB.ORDER[,25]*TAB.ORDER[,20]),2)


#---------------------------------------------------------------------------------------------------------------
#                                       Descriptive Statistics
#---------------------------------------------------------------------------------------------------------------

summary(TAB.ORDER[sapply(TAB.ORDER,is.numeric)]) # Select only numeric columns


# --------------------------------------------------------------------------------------------------------------
#                            Relationship b/n Mean & Standard deviation : Chebyshev's Theorem
# --------------------------------------------------------------------------------------------------------------

library(psych)
describe(TAB.ORDER$Sales_Units); # mean = 25.57 & sd = 14.48
# What proportion of data that have sales units between 0 & 40
K <-  1.5    # (30-mean(TAB.ORDER$Sales_Units))/sd(TAB.ORDER$Sales_Units)

# Chebyshev's inequality : 1-(1/K^2)
Cheb.In <- paste0((1-(1/K^2))*100,"%")

# Interpretation : ~56% of the data have sales units between 0 to 40. (OR)
# Approximately 56% of observations will lie within 1.5*standard deviation of the mean. 

#---------------------------------------------------------------------------------------------------------------
#                                       Distribution of Variables : Histogram
#---------------------------------------------------------------------------------------------------------------

hist(log(TAB.ORDER$Sales_Dollar),prob=T,xlab="Sales_Dollar",main="Sales $ distribution")
curve(dnorm(x,mean=mean(log(TAB.ORDER$Sales)),sd=sd(log(TAB.ORDER$Sales))),add=TRUE)

hist(log(TAB.ORDER$Sale_Units),prob=T,xlab="Sale_Units",main="Sale Units distribution")
curve(dnorm(x,mean=mean(log(TAB.ORDER$Sales)),sd=sd(log(TAB.ORDER$Sales))),add=TRUE)

hist(TAB.ORDER$Discount,prob=T,xlab="Discount",main="Discount distribution")
curve(dnorm(x,mean=mean(TAB.ORDER$Discount),sd=sd(TAB.ORDER$Discount)),add=TRUE)

hist(log(TAB.ORDER$Unit_Price),prob=T,xlab="Unit_Price",main="Unit Price distribution")
curve(dnorm(x,mean=mean(log(TAB.ORDER$Unit_Price)),sd=sd(log(TAB.ORDER$Unit_Price))),add=TRUE)

hist(log(TAB.ORDER$Shipping_Cost),prob=T,xlab="Shipping_Cost",main="Shipping Cost distribution")
curve(dnorm(x,mean=mean(log(TAB.ORDER$Shipping_Cost)),sd=sd(log(TAB.ORDER$Shipping_Cost))),add=TRUE)

hist(TAB.ORDER$Product_Base_Margin,prob=T,xlab="Product_Base_Margin",main="Base Margin distribution")
curve(dnorm(x,mean=mean(TAB.ORDER$Product_Base_Margin,na.rm=T),sd=sd(TAB.ORDER$Product_Base_Margin,na.rm=T)),add=TRUE)

hist(TAB.ORDER$Profit,prob=T,xlab="Profit",main="Profit distribution")
curve(dnorm(x,mean=mean(TAB.ORDER$Profit),sd=sd(TAB.ORDER$Profit)),add=TRUE)

# --------------------------------------------------------------------------------------------------------------
# --------------------------------------------------------------------------------------------------------------
# ----------------- END ------------------ Linear Regression ----------------- END ------------------------------
# --------------------------------------------------------------------------------------------------------------
# --------------------------------------------------------------------------------------------------------------


# --------------------------------------------------------------------------------------------------------------
# --------------------------------------------------------------------------------------------------------------
#                                         Logistic Regression
# --------------------------------------------------------------------------------------------------------------
# --------------------------------------------------------------------------------------------------------------

#---------------------------------------------------------------------------------------------------------------
#                                         Data and data types
#---------------------------------------------------------------------------------------------------------------

Results <- read.csv("http://www.ats.ucla.edu/stat/data/binary.csv")

data(Results);Results
str(Results)
Results$rank <- as.factor(Results$rank)
Results$admit <- as.factor(Results$admit)
  
#---------------------------------------------------------------------------------------------------------------
#                                       Descriptive Statistics
#---------------------------------------------------------------------------------------------------------------

summary(Results[,sapply(Results,is.numeric)])

#---------------------------------------------------------------------------------------------------------------
#                                       Distribution of Variables : Histogram
#---------------------------------------------------------------------------------------------------------------

par(mfrow=c(2,1),mar=c(3,2,2,1))
hist(Results$gre,prob=T,xlab="gre",main="gre distribution")
curve(dnorm(x,mean=mean(Results$gre),sd=sd(Results$gre)),add=TRUE)
hist(log(Results$gre),prob=T,xlab="log(gre)",main="log(gre) distribution")
curve(dnorm(x,mean=mean(log(Results$gre)),sd=sd(log(Results$gre))),add=TRUE)

par(mfrow=c(2,1),mar=c(3,2,2,1))
hist(Results$gpa,prob=T,xlab="gpa",main="gpa distribution")
curve(dnorm(x,mean=mean(Results$gpa),sd=sd(Results$gpa)),add=TRUE)
hist(log(Results$gpa),prob=T,xlab="log(gpa)",main="log(gpa) distribution")
curve(dnorm(x,mean=mean(log(Results$gpa)),sd=sd(log(Results$gpa))),add=TRUE)

table(Results$admit);table(Results$rank)'table(Results$admit,Results$rank)'

#---------------------------------------------------------------------------------------------------------------
#                                        BootStrapping/Data Sampling
#---------------------------------------------------------------------------------------------------------------

# Set up the non-parametric bootstrap
Results$admit <- ifelse(Results$admit==1,0,1)
library(boot)
logit.bootstrap <- function(data, indices) {
  
  d <- data[indices, ]
  fit <- glm(admit ~ gre + gpa + rank, data = d, family = "binomial")
  
  return(coef(fit))
}

set.seed(12345) # seed for the RNG to ensure that you get exactly the same results as here

logit.boot <- boot(data=Results, statistic=logit.bootstrap, R=10000) # 10'000 samples


# Data Sampling  ##
set.seed(400)
Results_IND <- sample(nrow(Results),size=round(((nrow(Results)/100)*70)+1,0))

Results_TRAIN <- Results[Results_IND,]

Results_TEST <- Results[-Results_IND,]

#---------------------------------------------------------------------------------------------------------------
#                                         Model building
#---------------------------------------------------------------------------------------------------------------

My_Logit <- glm(admit ~ ., data=Results_TRAIN,family=binomial)
summary(My_Logit)
#Interpretation : For one unit change in gre, log odds of admit will increases by 0.0019
#                 For one unit change in gpa, log odds of admit will increases by 0.984439
#                 For rank2, log odds of admit will increases by -0.831731
#                 For rank3, log odds of admit will increases by -1.323668
#                 For rank4, log odds of admit will increases by -1.756235

#---------------------------------------------------------------------------------------------------------------
#                                         Odds ratio and CI
#---------------------------------------------------------------------------------------------------------------

exp(cbind(OR = coef(My_Logit), confint(My_Logit)))

#Interpretation : 
# For one unit increase in gre, odds of admition to graduate school will increases by 1.00196667/0.001%
# For one unit increase in gpa, odds of admition to gpa school will increases by 2.67630890/167%
# For rank2, odds of admition to rank2 school will increases by 0.43529531/43%
# For rank3, odds of admition to rank3 school will increases by 0.26615726/27%
# For rank4, odds of admition to rank4 school will increases by 0.17269375/17%

#---------------------------------------------------------------------------------------------------------------
#                                         Predictions
#---------------------------------------------------------------------------------------------------------------

predict(My_Logit,newdata=Results_TEST,type="response")
Final <- data.frame(Results_TEST,actual=Results_TEST$admit,
            prob=round(predict(My_Logit,newdata=Results_TEST,type="response"),2),row.names=NULL)
Final$OddsRatio <- round(Final$prob/(1-Final$prob),2)
Final$Odds <- round(ifelse(Final$OddsRatio<=1,Final$OddsRatio*100,(Final$OddsRatio*100)-100),2)
predict(My_Logit,newdata=Results_TEST,type="terms")

# --------------------------------------------------------------------------------------------------------------
# --------------------------------------------------------------------------------------------------------------
# ----------------- END ----------------- Logistic Regression ----------------- END ------------------------------
# --------------------------------------------------------------------------------------------------------------
# --------------------------------------------------------------------------------------------------------------



# --------------------------------------------------------------------------------------------------------------
# --------------------------------------------------------------------------------------------------------------
#                                       Learning SQL
# --------------------------------------------------------------------------------------------------------------
# --------------------------------------------------------------------------------------------------------------

# --------------------------------------------------------------------------------------------------------------
#                                       Subset data
# --------------------------------------------------------------------------------------------------------------

sqldf('select * from CO2 where treatment=="nonchilled" and Plant=="Qn1"')
sqldf('select * from CO2 where treatment=="nonchilled"')

# --------------------------------------------------------------------------------------------------------------
#                                       Renaming variables
# --------------------------------------------------------------------------------------------------------------

Plant_new <- sqldf('select Plant from CO2')
CO2_New <- sqldf('ALTER TABLE CO2 ADD Plant_new nchar(30)')

# --------------------------------------------------------------------------------------------------------------
#                                       Merge two tables
# --------------------------------------------------------------------------------------------------------------

mtcars_Sub <- data.frame(mtcars[,2:5],row.names=NULL)
CO2_Merge <- sqldf('select * from CO2 LEFT JOIN mtcars_Sub on CO2.Plant=mtcars_Sub.cyl')

# --------------------------------------------------------------------------------------------------------------
# --------------------------------------------------------------------------------------------------------------
# ----------------- END ----------------- Learning SQL ----------------- END ------------------------------
# --------------------------------------------------------------------------------------------------------------
# --------------------------------------------------------------------------------------------------------------


# --------------------------------------------------------------------------------------------------------------
# --------------------------------------------------------------------------------------------------------------
#                                       Chi-Sqaure Test for Independence
# --------------------------------------------------------------------------------------------------------------
# --------------------------------------------------------------------------------------------------------------

library(MASS)
data(survey);survey
Survey_CT <- table(survey$Smoke,survey$Exer)

# --------------------------------------------------------------------------------------------------------------
#   Hypothesis H_0 : Students smoking habit is Independent of their Exercise level
#   Hypothesis H_1 : Students smoking habit is not Independent of their Exercise level    
# --------------------------------------------------------------------------------------------------------------

# --------------------------------------------------------------------------------------------------------------
# Solution : Chi-Squared test function
# --------------------------------------------------------------------------------------------------------------

chisq.test(Survey_CT)

# --------------------------------------------------------------------------------------------------------------
# Conclusion/Interpretation : Since P--value is greater than 0.05, we fail to reject NH. We conclude
#   that, students smoking habit is not Independent of their Exercise level
# --------------------------------------------------------------------------------------------------------------
# --------------------------------------------------------------------------------------------------------------
# ----------------- END -------------- Chi-Sqaure Test for Independence -------------- END ---------------------
# --------------------------------------------------------------------------------------------------------------
# --------------------------------------------------------------------------------------------------------------

# --------------------------------------------------------------------------------------------------------------
# --------------------------------------------------------------------------------------------------------------
#                                                Paired-t-test
# --------------------------------------------------------------------------------------------------------------
# --------------------------------------------------------------------------------------------------------------





# --------------------------------------------------------------------------------------------------------------
# --------------------------------------------------------------------------------------------------------------
# ----------------- END ------------------------ Paired-t-test -------------- END ------------------------------
# --------------------------------------------------------------------------------------------------------------
# --------------------------------------------------------------------------------------------------------------

#---------------------------------------------------------------------------------------------------------------
#                                     Correlation for each subsets of data
#---------------------------------------------------------------------------------------------------------------

Sample <- TAB.ORDER[1:1000,c(9,15:18)]
Sample$Product_Base_Margin[is.na(Sample$Product_Base_Margin)] <- 0.05
Sample$Region <- as.factor(Sample$Region)


Split_Sample <- split(Sample[,c(2:5)],as.factor(Sample$Region))
lapply(Split_Sample,cor)

# --------------------------------------------------------------------------------------------------------------
# --------------------------------------------------------------------------------------------------------------
# --------------------------------------------------------------------------------------------------------------
# --------------------------------------------------------------------------------------------------------------

#---------------------------------------------------------------------------------------------------------------
#                                               Learn Swirl
#---------------------------------------------------------------------------------------------------------------


# --------------------------------------------------------------------------------------------------------------
# --------------------------------------------------------------------------------------------------------------
# ----------------- END ---------------------- Learn Swirl -------------- END ----------------------------------
# --------------------------------------------------------------------------------------------------------------
# --------------------------------------------------------------------------------------------------------------



# --------------------------------------------------------------------------------------------------------------
# --------------------------------------------------------------------------------------------------------------
# --------------------------------------------------------------------------------------------------------------
# --------------------------------------------------------------------------------------------------------------
# --------------------------------------------------------------------------------------------------------------
# --------------------------------------------------------------------------------------------------------------
# --------------------------------------------------------------------------------------------------------------
# --------------------------------------------------------------------------------------------------------------
